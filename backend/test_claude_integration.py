#!/usr/bin/env python3
"""
æ¸¬è©¦ Claude API æ•´åˆçš„ç°¡å–®è…³æœ¬
ä½¿ç”¨å‰è«‹å…ˆè¨­å®šç’°å¢ƒè®Šæ•¸ï¼š
- LLM_PROVIDER=anthropic
- ANTHROPIC_API_KEY=your-claude-api-key
"""

import asyncio
import os
import sys
from pathlib import Path

# åŠ å…¥å°ˆæ¡ˆè·¯å¾‘ä»¥ä¾¿åŒ¯å…¥æ¨¡çµ„
sys.path.insert(0, str(Path(__file__).parent))

async def test_claude_integration():
    """æ¸¬è©¦ Claude API æ•´åˆ"""
    
    # è¨­å®šæ¸¬è©¦ç’°å¢ƒè®Šæ•¸
    os.environ["USE_MOCK_API"] = "false"
    os.environ["LLM_PROVIDER"] = "anthropic"
    
    # æª¢æŸ¥ API Key æ˜¯å¦è¨­å®š
    if not os.getenv("ANTHROPIC_API_KEY"):
        print("âŒ è«‹å…ˆè¨­å®š ANTHROPIC_API_KEY ç’°å¢ƒè®Šæ•¸")
        return False
    
    try:
        # åŒ¯å…¥ç›¸é—œæ¨¡çµ„
        from app.core.llm_client import generate_questions_by_type
        from app.schemas.question import QuestionType, Subject
        
        print("âœ… æˆåŠŸåŒ¯å…¥ç›¸é—œæ¨¡çµ„")
        
        # æ¸¬è©¦è³‡æ–™
        test_context = """
        äººå·¥æ™ºæ…§æ˜¯ä¸€é–€è®“æ©Ÿå™¨è¡¨ç¾å‡ºé¡ä¼¼äººé¡æ™ºæ…§è¡Œç‚ºçš„ç§‘å­¸æŠ€è¡“ã€‚
        å®ƒåŒ…å«æ©Ÿå™¨å­¸ç¿’ã€æ·±åº¦å­¸ç¿’ã€è‡ªç„¶èªè¨€è™•ç†ç­‰å¤šå€‹é ˜åŸŸã€‚
        è¿‘å¹´ä¾†ï¼ŒAI åœ¨é†«ç™‚è¨ºæ–·ã€è‡ªå‹•é§•é§›ã€èªéŸ³è¾¨è­˜ç­‰æ–¹é¢éƒ½æœ‰é‡å¤§çªç ´ã€‚
        """
        
        # æ¸¬è©¦ç”Ÿæˆå–®é¸é¡Œ
        print("\nğŸ§ª é–‹å§‹æ¸¬è©¦ç”Ÿæˆå–®é¸é¡Œ...")
        questions = await generate_questions_by_type(
            context=test_context,
            question_type=QuestionType.SINGLE_CHOICE,
            count=2,
            subject=Subject.HEALTH
        )
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(questions)} é“å–®é¸é¡Œ")
        for i, q in enumerate(questions, 1):
            print(f"  é¡Œç›® {i}: {q.get('prompt', 'N/A')[:50]}...")
        
        # æ¸¬è©¦ç”Ÿæˆç°¡ç­”é¡Œ
        print("\nğŸ§ª é–‹å§‹æ¸¬è©¦ç”Ÿæˆç°¡ç­”é¡Œ...")
        questions = await generate_questions_by_type(
            context=test_context,
            question_type=QuestionType.SHORT_ANSWER,
            count=1,
            subject=Subject.ENGLISH
        )
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(questions)} é“ç°¡ç­”é¡Œ")
        for i, q in enumerate(questions, 1):
            print(f"  é¡Œç›® {i}: {q.get('prompt', 'N/A')[:50]}...")
            
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_openai_integration():
    """æ¸¬è©¦ OpenAI API æ•´åˆï¼ˆå°ç…§æ¸¬è©¦ï¼‰"""
    
    # è¨­å®šæ¸¬è©¦ç’°å¢ƒè®Šæ•¸
    os.environ["USE_MOCK_API"] = "false"
    os.environ["LLM_PROVIDER"] = "openai"
    
    # æª¢æŸ¥ API Key æ˜¯å¦è¨­å®š
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  æœªè¨­å®š OPENAI_API_KEYï¼Œè·³é OpenAI æ¸¬è©¦")
        return True
    
    try:
        # åŒ¯å…¥ç›¸é—œæ¨¡çµ„
        from app.core.llm_client import generate_questions_by_type
        from app.schemas.question import QuestionType, Subject
        
        # æ¸¬è©¦è³‡æ–™
        test_context = """
        Python æ˜¯ä¸€ç¨®é«˜éšç¨‹å¼èªè¨€ï¼Œå…·æœ‰ç°¡æ½”æ˜“è®€çš„èªæ³•ã€‚
        å®ƒå»£æ³›æ‡‰ç”¨æ–¼ç¶²é é–‹ç™¼ã€è³‡æ–™ç§‘å­¸ã€äººå·¥æ™ºæ…§ç­‰é ˜åŸŸã€‚
        Python æ”¯æ´ç‰©ä»¶å°å‘ã€å‡½æ•¸å¼å’Œç¨‹åºå¼ç¨‹å¼è¨­è¨ˆç¯„å¼ã€‚
        """
        
        print("\nğŸ§ª é–‹å§‹æ¸¬è©¦ OpenAI ç”Ÿæˆé¡Œç›®...")
        questions = await generate_questions_by_type(
            context=test_context,
            question_type=QuestionType.CLOZE,
            count=1,
            subject=Subject.ENGLISH
        )
        
        print(f"âœ… OpenAI æˆåŠŸç”Ÿæˆ {len(questions)} é“é¡Œç›®")
        return True
        
    except Exception as e:
        print(f"âŒ OpenAI æ¸¬è©¦å¤±æ•—: {e}")
        return False

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ LLM æ•´åˆæ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦ Claude æ•´åˆ
    claude_success = await test_claude_integration()
    
    # æ¸¬è©¦ OpenAI æ•´åˆï¼ˆå°ç…§ï¼‰
    openai_success = await test_openai_integration()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ:")
    print(f"  Claude API: {'âœ… é€šé' if claude_success else 'âŒ å¤±æ•—'}")
    print(f"  OpenAI API: {'âœ… é€šé' if openai_success else 'âŒ å¤±æ•—'}")
    
    if claude_success:
        print("\nğŸ‰ Claude API æ•´åˆæˆåŠŸï¼")
        print("ä½¿ç”¨æ–¹å¼ï¼š")
        print("  1. åœ¨ .env ä¸­è¨­å®š LLM_PROVIDER=anthropic")
        print("  2. åœ¨ .env ä¸­è¨­å®š ANTHROPIC_API_KEY=your-key")
        print("  3. é‡å•Ÿæœå‹™å³å¯ä½¿ç”¨ Claude API")

if __name__ == "__main__":
    asyncio.run(main())